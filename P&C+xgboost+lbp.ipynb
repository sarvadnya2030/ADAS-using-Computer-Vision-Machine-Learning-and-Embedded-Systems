{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50c8f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage.feature import local_binary_pattern\n",
    "from scipy.stats import itemfreq\n",
    "from sklearn.preprocessing import normalize\n",
    "import csv\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14aee8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.2-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 297.1 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/admin-/anaconda3/lib/python3.9/site-packages (from xgboost) (1.7.1)\n",
      "Requirement already satisfied: numpy in /home/admin-/anaconda3/lib/python3.9/site-packages (from xgboost) (1.20.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a4485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lbp definiton for positve trainging images\n",
    "def lbp_positive(folder_name,radius, no_points ):\n",
    "    i=0\n",
    "    label=1\n",
    "    for filename in os.listdir(folder_name):\n",
    "        #path\n",
    "        path=os.path.join(folder_name,filename)\n",
    "        \n",
    "        #read the image\n",
    "        a=cv2.imread(path)\n",
    "        \n",
    "        #change the image from rgb to grayscale\n",
    "        a = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #apply gaussian filter\n",
    "        img_gaussian = cv2.GaussianBlur(a,(3,3),0)\n",
    "        \n",
    "        #define the kernel for prewitt edge detection operator\n",
    "        kernelx = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])\n",
    "        kernely = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
    "        img_prewittx = cv2.filter2D(img_gaussian, -1, kernelx)\n",
    "        img_prewitty = cv2.filter2D(img_gaussian, -1, kernely)\n",
    "        prewitt = img_prewittx + img_prewitty\n",
    "        \n",
    "        #apply canny edge detection.\n",
    "        img_canny = cv2.Canny(a,100,200)\n",
    "        final_img = prewitt + img_canny\n",
    "        \n",
    "        #set radius for LBP\n",
    "        #radius = 3\n",
    "        \n",
    "        # Number of points to be considered as neighbourers \n",
    "        #no_points = 8 * radius\n",
    "        \n",
    "        # Uniform LBP is used\n",
    "        lbp = local_binary_pattern(final_img, no_points, radius, method='uniform')\n",
    "        \n",
    "        # Calculate the histogram\n",
    "        x = itemfreq(lbp.ravel())\n",
    "        \n",
    "        # Normalize the histogram\n",
    "        hist = x[:, 1]/sum(x[:, 1])\n",
    "        \n",
    "        hist.reshape(26,-1)\n",
    "        hist = np.append(hist, label)\n",
    "        #writing features to csv files\n",
    "        with open(r'finalcsv.csv', 'a',newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(hist)\n",
    "        i=i+1\n",
    "        if i==3000:\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9691569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lbp definition for negative training images\n",
    "def lbp_negative(folder_name,radius, no_points ):\n",
    "    i=0\n",
    "    label=0\n",
    "    for filename in os.listdir(folder_name):\n",
    "        #path\n",
    "        path=os.path.join(folder_name,filename)\n",
    "        \n",
    "        #read the image\n",
    "        a=cv2.imread(path)\n",
    "        \n",
    "        #change the image from rgb to grayscale\n",
    "        a = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #apply gaussian filter\n",
    "        img_gaussian = cv2.GaussianBlur(a,(3,3),0)\n",
    "        \n",
    "        #define the kernel for prewitt edge detection operator\n",
    "        kernelx = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])\n",
    "        kernely = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
    "        img_prewittx = cv2.filter2D(img_gaussian, -1, kernelx)\n",
    "        img_prewitty = cv2.filter2D(img_gaussian, -1, kernely)\n",
    "        prewitt = img_prewittx + img_prewitty\n",
    "        \n",
    "        #apply canny edge detection.\n",
    "        img_canny = cv2.Canny(a,100,200)\n",
    "        final_img = prewitt + img_canny\n",
    "        \n",
    "        #set radius for LBP\n",
    "        #radius = 3\n",
    "        \n",
    "        # Number of points to be considered as neighbourers \n",
    "        #no_points = 8 * radius\n",
    "        \n",
    "        # Uniform LBP is used\n",
    "        lbp = local_binary_pattern(final_img, no_points, radius, method='uniform')\n",
    "        \n",
    "        # Calculate the histogram\n",
    "        x = itemfreq(lbp.ravel())\n",
    "        \n",
    "        # Normalize the histogram\n",
    "        hist = x[:, 1]/sum(x[:, 1])\n",
    "        \n",
    "        hist.reshape(26,-1)\n",
    "        hist = np.append(hist, label)\n",
    "        #writing features to csv files\n",
    "        with open(r'finalcsv.csv', 'a',newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(hist)\n",
    "        i=i+1\n",
    "        if i==3000:\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c8f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49692/8429825.py:39: DeprecationWarning: `itemfreq` is deprecated!\n",
      "`itemfreq` is deprecated and will be removed in a future version. Use instead `np.unique(..., return_counts=True)`\n",
      "  x = itemfreq(lbp.ravel())\n"
     ]
    }
   ],
   "source": [
    "#calling the lbp function for positive trainging images\n",
    "lbp_positive(r\"/home/admin-/Downloads/cr\",3,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "431d21c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15888/2789158279.py:39: DeprecationWarning: `itemfreq` is deprecated!\n",
      "`itemfreq` is deprecated and will be removed in a future version. Use instead `np.unique(..., return_counts=True)`\n",
      "  x = itemfreq(lbp.ravel())\n"
     ]
    }
   ],
   "source": [
    "#calling the lbp function for negative training images\n",
    "lbp_negative(r\"/home/admin-/Downloads/nc\",3,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94bac232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053108</td>\n",
       "      <td>0.040787</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.014037</td>\n",
       "      <td>0.008537</td>\n",
       "      <td>0.006304</td>\n",
       "      <td>0.005121</td>\n",
       "      <td>0.006075</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004738</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>0.006092</td>\n",
       "      <td>0.007958</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>0.276442</td>\n",
       "      <td>0.431354</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066246</td>\n",
       "      <td>0.036338</td>\n",
       "      <td>0.026908</td>\n",
       "      <td>0.018775</td>\n",
       "      <td>0.011096</td>\n",
       "      <td>0.007471</td>\n",
       "      <td>0.006437</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>0.014238</td>\n",
       "      <td>0.244654</td>\n",
       "      <td>0.450087</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061510</td>\n",
       "      <td>0.035275</td>\n",
       "      <td>0.031329</td>\n",
       "      <td>0.019758</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.006463</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.009273</td>\n",
       "      <td>0.009171</td>\n",
       "      <td>0.304250</td>\n",
       "      <td>0.382694</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.053752</td>\n",
       "      <td>0.038779</td>\n",
       "      <td>0.023873</td>\n",
       "      <td>0.016562</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>0.007347</td>\n",
       "      <td>0.005662</td>\n",
       "      <td>0.005728</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>0.005027</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>0.007293</td>\n",
       "      <td>0.009873</td>\n",
       "      <td>0.011619</td>\n",
       "      <td>0.308381</td>\n",
       "      <td>0.408731</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.078686</td>\n",
       "      <td>0.032784</td>\n",
       "      <td>0.021990</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.009175</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002673</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.004064</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>0.021692</td>\n",
       "      <td>0.216302</td>\n",
       "      <td>0.532604</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>0.060769</td>\n",
       "      <td>0.026655</td>\n",
       "      <td>0.029755</td>\n",
       "      <td>0.022017</td>\n",
       "      <td>0.012529</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.003116</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.005641</td>\n",
       "      <td>0.006975</td>\n",
       "      <td>0.006560</td>\n",
       "      <td>0.408784</td>\n",
       "      <td>0.334823</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>0.051875</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.028362</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.013845</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.005351</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>0.005591</td>\n",
       "      <td>0.006848</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>0.009760</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.334319</td>\n",
       "      <td>0.382041</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>0.070167</td>\n",
       "      <td>0.035263</td>\n",
       "      <td>0.024682</td>\n",
       "      <td>0.019187</td>\n",
       "      <td>0.012544</td>\n",
       "      <td>0.009085</td>\n",
       "      <td>0.007278</td>\n",
       "      <td>0.007050</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.006392</td>\n",
       "      <td>0.010294</td>\n",
       "      <td>0.013598</td>\n",
       "      <td>0.017284</td>\n",
       "      <td>0.226108</td>\n",
       "      <td>0.459387</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>0.058628</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.024031</td>\n",
       "      <td>0.016965</td>\n",
       "      <td>0.011444</td>\n",
       "      <td>0.009329</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>0.008115</td>\n",
       "      <td>0.009976</td>\n",
       "      <td>0.012759</td>\n",
       "      <td>0.010901</td>\n",
       "      <td>0.279314</td>\n",
       "      <td>0.381289</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>0.070858</td>\n",
       "      <td>0.033725</td>\n",
       "      <td>0.026132</td>\n",
       "      <td>0.020513</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.008046</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>0.005759</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>0.007153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>0.005955</td>\n",
       "      <td>0.007521</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.015319</td>\n",
       "      <td>0.016220</td>\n",
       "      <td>0.231962</td>\n",
       "      <td>0.443848</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5400 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.053108  0.040787  0.023000  0.014037  0.008537  0.006304  0.005121   \n",
       "1     0.066246  0.036338  0.026908  0.018775  0.011096  0.007471  0.006437   \n",
       "2     0.061510  0.035275  0.031329  0.019758  0.010398  0.006463  0.004985   \n",
       "3     0.053752  0.038779  0.023873  0.016562  0.010079  0.007347  0.005662   \n",
       "4     0.078686  0.032784  0.021990  0.015850  0.009175  0.005313  0.003865   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5395  0.060769  0.026655  0.029755  0.022017  0.012529  0.007998  0.005773   \n",
       "5396  0.051875  0.022832  0.028362  0.020497  0.013845  0.007870  0.005258   \n",
       "5397  0.070167  0.035263  0.024682  0.019187  0.012544  0.009085  0.007278   \n",
       "5398  0.058628  0.026606  0.028126  0.024031  0.016965  0.011444  0.009329   \n",
       "5399  0.070858  0.033725  0.026132  0.020513  0.012359  0.008046  0.005919   \n",
       "\n",
       "            7         8         9   ...        17        18        19  \\\n",
       "0     0.006075  0.005525  0.006383  ...  0.004738  0.004075  0.004892   \n",
       "1     0.006104  0.005587  0.006308  ...  0.005208  0.004733  0.005692   \n",
       "2     0.005521  0.005360  0.006329  ...  0.003854  0.003400  0.004283   \n",
       "3     0.005728  0.005366  0.006193  ...  0.004749  0.004471  0.005027   \n",
       "4     0.003338  0.002805  0.002540  ...  0.002673  0.002904  0.004064   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5395  0.005405  0.005297  0.005645  ...  0.003056  0.003116  0.003679   \n",
       "5396  0.005391  0.005351  0.006600  ...  0.009676  0.004586  0.005591   \n",
       "5397  0.007050  0.007026  0.007122  ...  0.003926  0.003842  0.004704   \n",
       "5398  0.008857  0.008902  0.009788  ...  0.006022  0.005862  0.007096   \n",
       "5399  0.005759  0.006408  0.007153  ...  0.005126  0.004722  0.005955   \n",
       "\n",
       "            20        21        22        23        24        25   26  \n",
       "0     0.006092  0.007958  0.011371  0.011550  0.276442  0.431354  1.0  \n",
       "1     0.006917  0.008833  0.012483  0.014238  0.244654  0.450087  1.0  \n",
       "2     0.005031  0.007473  0.009273  0.009171  0.304250  0.382694  1.0  \n",
       "3     0.005795  0.007293  0.009873  0.011619  0.308381  0.408731  1.0  \n",
       "4     0.005693  0.008138  0.013242  0.021692  0.216302  0.532604  1.0  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "5395  0.004906  0.005641  0.006975  0.006560  0.408784  0.334823  0.0  \n",
       "5396  0.006848  0.008971  0.009760  0.006993  0.334319  0.382041  0.0  \n",
       "5397  0.006392  0.010294  0.013598  0.017284  0.226108  0.459387  0.0  \n",
       "5398  0.008115  0.009976  0.012759  0.010901  0.279314  0.381289  0.0  \n",
       "5399  0.007521  0.010941  0.015319  0.016220  0.231962  0.443848  0.0  \n",
       "\n",
       "[5400 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the csv file into 'data' variable\n",
    "data= pd.read_csv('/home/admin-/EDAI project/finalcsv.csv',header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19c01c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into x and y with 26 features for x and label column for y.\n",
    "x = data.iloc[:,0:26].values\n",
    "y = data.iloc[:,26].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5589f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the data with the help of standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_obj = StandardScaler()\n",
    "scalardata = std_obj.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d81d8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.36476046,  1.52397565, -0.80116289, ...,  0.0164222 ,\n",
       "        -0.59825639,  0.59356418],\n",
       "       [ 0.90452673,  0.84175173,  0.20363608, ...,  0.6501561 ,\n",
       "        -0.95707242,  0.86525568],\n",
       "       [ 0.4470117 ,  0.67886118,  1.3401944 , ..., -0.54460425,\n",
       "        -0.28435703, -0.11216294],\n",
       "       ...,\n",
       "       [ 1.28333569,  0.67699933, -0.3688367 , ...,  1.36861705,\n",
       "        -1.16641631,  1.00012252],\n",
       "       [ 0.16854777, -0.65017321,  0.51670261, ..., -0.13665465,\n",
       "        -0.56583229, -0.1325424 ],\n",
       "       [ 1.35014969,  0.4412341 ,  0.00398991, ...,  1.11758012,\n",
       "        -1.10034034,  0.77475948]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing the standardized data\n",
    "scalardata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2949958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing sklearn function for pca\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aa0785a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying PCA to reduce dimensions\n",
    "pca = PCA(n_components=None)\n",
    "pca.fit(scalardata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbab7569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.28476084e-01, -9.53553025e-01,  2.48426100e+00, ...,\n",
       "         6.52763794e-02, -1.06223038e-03,  2.56756419e-15],\n",
       "       [ 7.30490027e-01, -2.33696554e+00, -1.97356780e-01, ...,\n",
       "         3.94571350e-02,  4.15240142e-03,  2.31948814e-15],\n",
       "       [ 5.63921676e-01,  7.24388245e-01,  9.08377478e-01, ...,\n",
       "        -2.59474032e-02, -1.33779597e-02,  2.57457776e-15],\n",
       "       ...,\n",
       "       [ 1.06160004e+00, -2.83266057e+00, -6.17287567e-01, ...,\n",
       "        -3.58438991e-02, -1.77834303e-01,  5.77652571e-16],\n",
       "       [ 6.32558139e+00, -8.44123900e-01, -1.19717324e+00, ...,\n",
       "         1.28985857e-01, -2.40708418e-02,  1.84443629e-15],\n",
       "       [ 1.83370913e+00, -3.29135138e+00, -1.93554363e-01, ...,\n",
       "        -8.46339129e-02,  3.61822953e-02,  1.95997319e-15]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_scalardata = pca.transform(scalardata)\n",
    "new_scalardata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae24e5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 26)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_scalardata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b275a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scalardata = pd.DataFrame(new_scalardata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c444d222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.128476</td>\n",
       "      <td>-0.953553</td>\n",
       "      <td>2.484261</td>\n",
       "      <td>-0.938782</td>\n",
       "      <td>0.429984</td>\n",
       "      <td>0.378784</td>\n",
       "      <td>-0.554473</td>\n",
       "      <td>-0.254278</td>\n",
       "      <td>0.013919</td>\n",
       "      <td>0.327864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080958</td>\n",
       "      <td>-0.214992</td>\n",
       "      <td>0.242315</td>\n",
       "      <td>0.214886</td>\n",
       "      <td>-0.084963</td>\n",
       "      <td>0.029901</td>\n",
       "      <td>0.056115</td>\n",
       "      <td>0.065276</td>\n",
       "      <td>-0.001062</td>\n",
       "      <td>2.567564e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.730490</td>\n",
       "      <td>-2.336966</td>\n",
       "      <td>-0.197357</td>\n",
       "      <td>-0.099710</td>\n",
       "      <td>0.042322</td>\n",
       "      <td>0.420716</td>\n",
       "      <td>-0.017422</td>\n",
       "      <td>0.020909</td>\n",
       "      <td>-0.061947</td>\n",
       "      <td>0.226997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073002</td>\n",
       "      <td>-0.184407</td>\n",
       "      <td>0.052280</td>\n",
       "      <td>-0.046525</td>\n",
       "      <td>0.160226</td>\n",
       "      <td>-0.185574</td>\n",
       "      <td>0.031686</td>\n",
       "      <td>0.039457</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>2.319488e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.563922</td>\n",
       "      <td>0.724388</td>\n",
       "      <td>0.908377</td>\n",
       "      <td>-2.165524</td>\n",
       "      <td>2.412024</td>\n",
       "      <td>-0.565519</td>\n",
       "      <td>0.513390</td>\n",
       "      <td>-0.153776</td>\n",
       "      <td>-0.250971</td>\n",
       "      <td>0.204393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034748</td>\n",
       "      <td>0.018079</td>\n",
       "      <td>0.238624</td>\n",
       "      <td>-0.152767</td>\n",
       "      <td>-0.066965</td>\n",
       "      <td>0.014533</td>\n",
       "      <td>0.053750</td>\n",
       "      <td>-0.025947</td>\n",
       "      <td>-0.013378</td>\n",
       "      <td>2.574578e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.057953</td>\n",
       "      <td>-0.408774</td>\n",
       "      <td>1.099041</td>\n",
       "      <td>-0.598434</td>\n",
       "      <td>-0.205021</td>\n",
       "      <td>0.854135</td>\n",
       "      <td>-0.445132</td>\n",
       "      <td>-0.308015</td>\n",
       "      <td>0.131580</td>\n",
       "      <td>-0.219747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035859</td>\n",
       "      <td>-0.062878</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>-0.005593</td>\n",
       "      <td>0.018508</td>\n",
       "      <td>-0.058088</td>\n",
       "      <td>-0.012220</td>\n",
       "      <td>-0.013122</td>\n",
       "      <td>-0.073147</td>\n",
       "      <td>-3.356616e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.676309</td>\n",
       "      <td>-4.075108</td>\n",
       "      <td>-1.300399</td>\n",
       "      <td>0.403183</td>\n",
       "      <td>-0.811104</td>\n",
       "      <td>-0.677178</td>\n",
       "      <td>0.810935</td>\n",
       "      <td>-0.066891</td>\n",
       "      <td>0.501818</td>\n",
       "      <td>0.045705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088755</td>\n",
       "      <td>-0.010662</td>\n",
       "      <td>-0.012330</td>\n",
       "      <td>-0.003450</td>\n",
       "      <td>0.027476</td>\n",
       "      <td>-0.008440</td>\n",
       "      <td>-0.006929</td>\n",
       "      <td>-0.067044</td>\n",
       "      <td>0.012137</td>\n",
       "      <td>9.009987e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>-1.677530</td>\n",
       "      <td>2.298283</td>\n",
       "      <td>-2.470454</td>\n",
       "      <td>-0.711787</td>\n",
       "      <td>-0.034619</td>\n",
       "      <td>0.018352</td>\n",
       "      <td>0.011348</td>\n",
       "      <td>-0.178542</td>\n",
       "      <td>-0.217511</td>\n",
       "      <td>-0.075501</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093042</td>\n",
       "      <td>-0.140242</td>\n",
       "      <td>-0.123634</td>\n",
       "      <td>0.072497</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>-0.166589</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>-0.090090</td>\n",
       "      <td>-0.082518</td>\n",
       "      <td>-8.750743e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>2.563273</td>\n",
       "      <td>0.642886</td>\n",
       "      <td>-0.114482</td>\n",
       "      <td>2.374667</td>\n",
       "      <td>0.664604</td>\n",
       "      <td>2.437336</td>\n",
       "      <td>2.402342</td>\n",
       "      <td>0.822720</td>\n",
       "      <td>0.693345</td>\n",
       "      <td>0.205482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276381</td>\n",
       "      <td>0.084063</td>\n",
       "      <td>-0.088606</td>\n",
       "      <td>-0.051174</td>\n",
       "      <td>-0.007274</td>\n",
       "      <td>-0.134906</td>\n",
       "      <td>-0.096434</td>\n",
       "      <td>0.157186</td>\n",
       "      <td>-0.123722</td>\n",
       "      <td>1.570965e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>1.061600</td>\n",
       "      <td>-2.832661</td>\n",
       "      <td>-0.617288</td>\n",
       "      <td>-0.625660</td>\n",
       "      <td>-1.056084</td>\n",
       "      <td>-1.082804</td>\n",
       "      <td>-0.204459</td>\n",
       "      <td>0.854091</td>\n",
       "      <td>-0.230621</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214487</td>\n",
       "      <td>0.256306</td>\n",
       "      <td>-0.181507</td>\n",
       "      <td>-0.206344</td>\n",
       "      <td>0.042204</td>\n",
       "      <td>-0.142217</td>\n",
       "      <td>-0.230129</td>\n",
       "      <td>-0.035844</td>\n",
       "      <td>-0.177834</td>\n",
       "      <td>5.776526e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>6.325581</td>\n",
       "      <td>-0.844124</td>\n",
       "      <td>-1.197173</td>\n",
       "      <td>0.377364</td>\n",
       "      <td>-1.109529</td>\n",
       "      <td>-0.497345</td>\n",
       "      <td>-0.451555</td>\n",
       "      <td>0.381003</td>\n",
       "      <td>-0.173963</td>\n",
       "      <td>-0.055648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.288996</td>\n",
       "      <td>-0.059291</td>\n",
       "      <td>0.138696</td>\n",
       "      <td>0.038389</td>\n",
       "      <td>0.143562</td>\n",
       "      <td>-0.148784</td>\n",
       "      <td>-0.027999</td>\n",
       "      <td>0.128986</td>\n",
       "      <td>-0.024071</td>\n",
       "      <td>1.844436e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>1.833709</td>\n",
       "      <td>-3.291351</td>\n",
       "      <td>-0.193554</td>\n",
       "      <td>0.589598</td>\n",
       "      <td>0.168293</td>\n",
       "      <td>-0.764108</td>\n",
       "      <td>0.342735</td>\n",
       "      <td>0.124753</td>\n",
       "      <td>-0.555976</td>\n",
       "      <td>-0.264147</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131240</td>\n",
       "      <td>0.190355</td>\n",
       "      <td>-0.036732</td>\n",
       "      <td>0.062887</td>\n",
       "      <td>0.022722</td>\n",
       "      <td>-0.061009</td>\n",
       "      <td>0.015635</td>\n",
       "      <td>-0.084634</td>\n",
       "      <td>0.036182</td>\n",
       "      <td>1.959973e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5400 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.128476 -0.953553  2.484261 -0.938782  0.429984  0.378784 -0.554473   \n",
       "1     0.730490 -2.336966 -0.197357 -0.099710  0.042322  0.420716 -0.017422   \n",
       "2     0.563922  0.724388  0.908377 -2.165524  2.412024 -0.565519  0.513390   \n",
       "3    -0.057953 -0.408774  1.099041 -0.598434 -0.205021  0.854135 -0.445132   \n",
       "4    -5.676309 -4.075108 -1.300399  0.403183 -0.811104 -0.677178  0.810935   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5395 -1.677530  2.298283 -2.470454 -0.711787 -0.034619  0.018352  0.011348   \n",
       "5396  2.563273  0.642886 -0.114482  2.374667  0.664604  2.437336  2.402342   \n",
       "5397  1.061600 -2.832661 -0.617288 -0.625660 -1.056084 -1.082804 -0.204459   \n",
       "5398  6.325581 -0.844124 -1.197173  0.377364 -1.109529 -0.497345 -0.451555   \n",
       "5399  1.833709 -3.291351 -0.193554  0.589598  0.168293 -0.764108  0.342735   \n",
       "\n",
       "            7         8         9   ...        16        17        18  \\\n",
       "0    -0.254278  0.013919  0.327864  ... -0.080958 -0.214992  0.242315   \n",
       "1     0.020909 -0.061947  0.226997  ... -0.073002 -0.184407  0.052280   \n",
       "2    -0.153776 -0.250971  0.204393  ... -0.034748  0.018079  0.238624   \n",
       "3    -0.308015  0.131580 -0.219747  ... -0.035859 -0.062878  0.006159   \n",
       "4    -0.066891  0.501818  0.045705  ...  0.088755 -0.010662 -0.012330   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5395 -0.178542 -0.217511 -0.075501  ... -0.093042 -0.140242 -0.123634   \n",
       "5396  0.822720  0.693345  0.205482  ...  0.276381  0.084063 -0.088606   \n",
       "5397  0.854091 -0.230621  0.008330  ...  0.214487  0.256306 -0.181507   \n",
       "5398  0.381003 -0.173963 -0.055648  ... -0.288996 -0.059291  0.138696   \n",
       "5399  0.124753 -0.555976 -0.264147  ... -0.131240  0.190355 -0.036732   \n",
       "\n",
       "            19        20        21        22        23        24            25  \n",
       "0     0.214886 -0.084963  0.029901  0.056115  0.065276 -0.001062  2.567564e-15  \n",
       "1    -0.046525  0.160226 -0.185574  0.031686  0.039457  0.004152  2.319488e-15  \n",
       "2    -0.152767 -0.066965  0.014533  0.053750 -0.025947 -0.013378  2.574578e-15  \n",
       "3    -0.005593  0.018508 -0.058088 -0.012220 -0.013122 -0.073147 -3.356616e-15  \n",
       "4    -0.003450  0.027476 -0.008440 -0.006929 -0.067044  0.012137  9.009987e-16  \n",
       "...        ...       ...       ...       ...       ...       ...           ...  \n",
       "5395  0.072497  0.001323 -0.166589  0.024089 -0.090090 -0.082518 -8.750743e-16  \n",
       "5396 -0.051174 -0.007274 -0.134906 -0.096434  0.157186 -0.123722  1.570965e-15  \n",
       "5397 -0.206344  0.042204 -0.142217 -0.230129 -0.035844 -0.177834  5.776526e-16  \n",
       "5398  0.038389  0.143562 -0.148784 -0.027999  0.128986 -0.024071  1.844436e-15  \n",
       "5399  0.062887  0.022722 -0.061009  0.015635 -0.084634  0.036182  1.959973e-15  \n",
       "\n",
       "[5400 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_scalardata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6385e40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 26)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_scalardata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe466d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "#Initially the explained variance sum of the full data with 26 features comes out to be 1.\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5682ed91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.79904084e-01 2.12951366e-01 9.22497627e-02 3.85436929e-02\n",
      " 3.05158381e-02 1.26835505e-02 7.44364055e-03 5.44939073e-03\n",
      " 3.63468650e-03 3.12004640e-03 2.77181392e-03 2.03501420e-03\n",
      " 1.18107603e-03 1.10759523e-03 9.64386871e-04 8.11927700e-04\n",
      " 6.64380796e-04 6.33289567e-04 6.07999103e-04 5.95410751e-04\n",
      " 5.29716948e-04 4.73836118e-04 3.99085900e-04 3.82870260e-04\n",
      " 3.45538716e-04 1.66193439e-31]\n"
     ]
    }
   ],
   "source": [
    "#Initially the explained variance sum of the full data with 26 features comes out to be 1.\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbae9a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=20)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choosing only 18 columns from the data.\n",
    "pca = PCA(n_components=20)\n",
    "pca.fit(scalardata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34ad40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'PCA_3_Model.sav'\n",
    "pickle.dump(pca, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71e02cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12847608, -0.95355303,  2.484261  , ..., -0.21499233,\n",
       "         0.24231463,  0.21488625],\n",
       "       [ 0.73049003, -2.33696554, -0.19735678, ..., -0.18440678,\n",
       "         0.05228022, -0.04652485],\n",
       "       [ 0.56392168,  0.72438825,  0.90837748, ...,  0.0180794 ,\n",
       "         0.23862358, -0.15276742],\n",
       "       ...,\n",
       "       [ 1.06160004, -2.83266057, -0.61728757, ...,  0.25630618,\n",
       "        -0.18150717, -0.20634408],\n",
       "       [ 6.32558139, -0.8441239 , -1.19717324, ..., -0.05929087,\n",
       "         0.13869582,  0.03838929],\n",
       "       [ 1.83370913, -3.29135138, -0.19355436, ...,  0.19035461,\n",
       "        -0.03673238,  0.06288735]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_scalardata = pca.transform(scalardata)\n",
    "new_scalardata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a01bb385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 20)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_scalardata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "367ff40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9978689520592077\n"
     ]
    }
   ],
   "source": [
    "#explained variance sum of the data with 18 columns comes out to be 99%.\n",
    "print(pca.explained_variance_ratio_.sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3eaddbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.128476</td>\n",
       "      <td>-0.953553</td>\n",
       "      <td>2.484261</td>\n",
       "      <td>-0.938782</td>\n",
       "      <td>0.429984</td>\n",
       "      <td>0.378784</td>\n",
       "      <td>-0.554473</td>\n",
       "      <td>-0.254278</td>\n",
       "      <td>0.013919</td>\n",
       "      <td>0.327864</td>\n",
       "      <td>-0.278600</td>\n",
       "      <td>0.152302</td>\n",
       "      <td>-0.079568</td>\n",
       "      <td>-0.250151</td>\n",
       "      <td>-0.107531</td>\n",
       "      <td>-0.245801</td>\n",
       "      <td>-0.080958</td>\n",
       "      <td>-0.214992</td>\n",
       "      <td>0.242315</td>\n",
       "      <td>0.214886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.730490</td>\n",
       "      <td>-2.336966</td>\n",
       "      <td>-0.197357</td>\n",
       "      <td>-0.099710</td>\n",
       "      <td>0.042322</td>\n",
       "      <td>0.420716</td>\n",
       "      <td>-0.017422</td>\n",
       "      <td>0.020909</td>\n",
       "      <td>-0.061947</td>\n",
       "      <td>0.226997</td>\n",
       "      <td>0.081446</td>\n",
       "      <td>-0.255886</td>\n",
       "      <td>0.141114</td>\n",
       "      <td>-0.059088</td>\n",
       "      <td>0.066955</td>\n",
       "      <td>0.151233</td>\n",
       "      <td>-0.073002</td>\n",
       "      <td>-0.184407</td>\n",
       "      <td>0.052280</td>\n",
       "      <td>-0.046525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.563922</td>\n",
       "      <td>0.724388</td>\n",
       "      <td>0.908377</td>\n",
       "      <td>-2.165524</td>\n",
       "      <td>2.412024</td>\n",
       "      <td>-0.565519</td>\n",
       "      <td>0.513390</td>\n",
       "      <td>-0.153776</td>\n",
       "      <td>-0.250971</td>\n",
       "      <td>0.204393</td>\n",
       "      <td>-0.065595</td>\n",
       "      <td>-0.168926</td>\n",
       "      <td>-0.169644</td>\n",
       "      <td>-0.052725</td>\n",
       "      <td>-0.057067</td>\n",
       "      <td>-0.293405</td>\n",
       "      <td>-0.034748</td>\n",
       "      <td>0.018079</td>\n",
       "      <td>0.238624</td>\n",
       "      <td>-0.152767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.057953</td>\n",
       "      <td>-0.408774</td>\n",
       "      <td>1.099041</td>\n",
       "      <td>-0.598434</td>\n",
       "      <td>-0.205021</td>\n",
       "      <td>0.854135</td>\n",
       "      <td>-0.445132</td>\n",
       "      <td>-0.308015</td>\n",
       "      <td>0.131580</td>\n",
       "      <td>-0.219747</td>\n",
       "      <td>-0.024985</td>\n",
       "      <td>-0.049617</td>\n",
       "      <td>0.183280</td>\n",
       "      <td>-0.065502</td>\n",
       "      <td>-0.033485</td>\n",
       "      <td>0.071344</td>\n",
       "      <td>-0.035859</td>\n",
       "      <td>-0.062878</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>-0.005593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.676309</td>\n",
       "      <td>-4.075108</td>\n",
       "      <td>-1.300399</td>\n",
       "      <td>0.403183</td>\n",
       "      <td>-0.811104</td>\n",
       "      <td>-0.677178</td>\n",
       "      <td>0.810935</td>\n",
       "      <td>-0.066891</td>\n",
       "      <td>0.501818</td>\n",
       "      <td>0.045705</td>\n",
       "      <td>0.508965</td>\n",
       "      <td>0.027678</td>\n",
       "      <td>-0.092043</td>\n",
       "      <td>0.095098</td>\n",
       "      <td>-0.057876</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.088755</td>\n",
       "      <td>-0.010662</td>\n",
       "      <td>-0.012330</td>\n",
       "      <td>-0.003450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>-1.677530</td>\n",
       "      <td>2.298283</td>\n",
       "      <td>-2.470454</td>\n",
       "      <td>-0.711787</td>\n",
       "      <td>-0.034619</td>\n",
       "      <td>0.018352</td>\n",
       "      <td>0.011348</td>\n",
       "      <td>-0.178542</td>\n",
       "      <td>-0.217511</td>\n",
       "      <td>-0.075501</td>\n",
       "      <td>-0.060768</td>\n",
       "      <td>-0.098593</td>\n",
       "      <td>-0.068376</td>\n",
       "      <td>0.049699</td>\n",
       "      <td>0.072006</td>\n",
       "      <td>-0.001584</td>\n",
       "      <td>-0.093042</td>\n",
       "      <td>-0.140242</td>\n",
       "      <td>-0.123634</td>\n",
       "      <td>0.072497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>2.563273</td>\n",
       "      <td>0.642886</td>\n",
       "      <td>-0.114482</td>\n",
       "      <td>2.374667</td>\n",
       "      <td>0.664604</td>\n",
       "      <td>2.437336</td>\n",
       "      <td>2.402342</td>\n",
       "      <td>0.822720</td>\n",
       "      <td>0.693345</td>\n",
       "      <td>0.205482</td>\n",
       "      <td>-1.071011</td>\n",
       "      <td>-0.191605</td>\n",
       "      <td>-0.349451</td>\n",
       "      <td>0.191343</td>\n",
       "      <td>0.571275</td>\n",
       "      <td>-0.203902</td>\n",
       "      <td>0.276381</td>\n",
       "      <td>0.084063</td>\n",
       "      <td>-0.088606</td>\n",
       "      <td>-0.051174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>1.061600</td>\n",
       "      <td>-2.832661</td>\n",
       "      <td>-0.617288</td>\n",
       "      <td>-0.625660</td>\n",
       "      <td>-1.056084</td>\n",
       "      <td>-1.082804</td>\n",
       "      <td>-0.204459</td>\n",
       "      <td>0.854091</td>\n",
       "      <td>-0.230621</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>-0.750066</td>\n",
       "      <td>-0.007717</td>\n",
       "      <td>0.205836</td>\n",
       "      <td>-0.230538</td>\n",
       "      <td>0.077988</td>\n",
       "      <td>-0.344476</td>\n",
       "      <td>0.214487</td>\n",
       "      <td>0.256306</td>\n",
       "      <td>-0.181507</td>\n",
       "      <td>-0.206344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>6.325581</td>\n",
       "      <td>-0.844124</td>\n",
       "      <td>-1.197173</td>\n",
       "      <td>0.377364</td>\n",
       "      <td>-1.109529</td>\n",
       "      <td>-0.497345</td>\n",
       "      <td>-0.451555</td>\n",
       "      <td>0.381003</td>\n",
       "      <td>-0.173963</td>\n",
       "      <td>-0.055648</td>\n",
       "      <td>-0.103346</td>\n",
       "      <td>0.031517</td>\n",
       "      <td>0.116338</td>\n",
       "      <td>-0.223165</td>\n",
       "      <td>-0.094717</td>\n",
       "      <td>0.048993</td>\n",
       "      <td>-0.288996</td>\n",
       "      <td>-0.059291</td>\n",
       "      <td>0.138696</td>\n",
       "      <td>0.038389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>1.833709</td>\n",
       "      <td>-3.291351</td>\n",
       "      <td>-0.193554</td>\n",
       "      <td>0.589598</td>\n",
       "      <td>0.168293</td>\n",
       "      <td>-0.764108</td>\n",
       "      <td>0.342735</td>\n",
       "      <td>0.124753</td>\n",
       "      <td>-0.555976</td>\n",
       "      <td>-0.264147</td>\n",
       "      <td>-0.383646</td>\n",
       "      <td>-0.122895</td>\n",
       "      <td>-0.172447</td>\n",
       "      <td>-0.224528</td>\n",
       "      <td>-0.138194</td>\n",
       "      <td>0.087539</td>\n",
       "      <td>-0.131240</td>\n",
       "      <td>0.190355</td>\n",
       "      <td>-0.036732</td>\n",
       "      <td>0.062887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5400 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.128476 -0.953553  2.484261 -0.938782  0.429984  0.378784 -0.554473   \n",
       "1     0.730490 -2.336966 -0.197357 -0.099710  0.042322  0.420716 -0.017422   \n",
       "2     0.563922  0.724388  0.908377 -2.165524  2.412024 -0.565519  0.513390   \n",
       "3    -0.057953 -0.408774  1.099041 -0.598434 -0.205021  0.854135 -0.445132   \n",
       "4    -5.676309 -4.075108 -1.300399  0.403183 -0.811104 -0.677178  0.810935   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5395 -1.677530  2.298283 -2.470454 -0.711787 -0.034619  0.018352  0.011348   \n",
       "5396  2.563273  0.642886 -0.114482  2.374667  0.664604  2.437336  2.402342   \n",
       "5397  1.061600 -2.832661 -0.617288 -0.625660 -1.056084 -1.082804 -0.204459   \n",
       "5398  6.325581 -0.844124 -1.197173  0.377364 -1.109529 -0.497345 -0.451555   \n",
       "5399  1.833709 -3.291351 -0.193554  0.589598  0.168293 -0.764108  0.342735   \n",
       "\n",
       "            7         8         9         10        11        12        13  \\\n",
       "0    -0.254278  0.013919  0.327864 -0.278600  0.152302 -0.079568 -0.250151   \n",
       "1     0.020909 -0.061947  0.226997  0.081446 -0.255886  0.141114 -0.059088   \n",
       "2    -0.153776 -0.250971  0.204393 -0.065595 -0.168926 -0.169644 -0.052725   \n",
       "3    -0.308015  0.131580 -0.219747 -0.024985 -0.049617  0.183280 -0.065502   \n",
       "4    -0.066891  0.501818  0.045705  0.508965  0.027678 -0.092043  0.095098   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5395 -0.178542 -0.217511 -0.075501 -0.060768 -0.098593 -0.068376  0.049699   \n",
       "5396  0.822720  0.693345  0.205482 -1.071011 -0.191605 -0.349451  0.191343   \n",
       "5397  0.854091 -0.230621  0.008330 -0.750066 -0.007717  0.205836 -0.230538   \n",
       "5398  0.381003 -0.173963 -0.055648 -0.103346  0.031517  0.116338 -0.223165   \n",
       "5399  0.124753 -0.555976 -0.264147 -0.383646 -0.122895 -0.172447 -0.224528   \n",
       "\n",
       "            14        15        16        17        18        19  \n",
       "0    -0.107531 -0.245801 -0.080958 -0.214992  0.242315  0.214886  \n",
       "1     0.066955  0.151233 -0.073002 -0.184407  0.052280 -0.046525  \n",
       "2    -0.057067 -0.293405 -0.034748  0.018079  0.238624 -0.152767  \n",
       "3    -0.033485  0.071344 -0.035859 -0.062878  0.006159 -0.005593  \n",
       "4    -0.057876  0.002760  0.088755 -0.010662 -0.012330 -0.003450  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "5395  0.072006 -0.001584 -0.093042 -0.140242 -0.123634  0.072497  \n",
       "5396  0.571275 -0.203902  0.276381  0.084063 -0.088606 -0.051174  \n",
       "5397  0.077988 -0.344476  0.214487  0.256306 -0.181507 -0.206344  \n",
       "5398 -0.094717  0.048993 -0.288996 -0.059291  0.138696  0.038389  \n",
       "5399 -0.138194  0.087539 -0.131240  0.190355 -0.036732  0.062887  \n",
       "\n",
       "[5400 rows x 20 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting the data into dataframe\n",
    "new_scalardata = pd.DataFrame(new_scalardata)\n",
    "new_scalardata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3c3286c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.128476</td>\n",
       "      <td>-0.953553</td>\n",
       "      <td>2.484261</td>\n",
       "      <td>-0.938782</td>\n",
       "      <td>0.429984</td>\n",
       "      <td>0.378784</td>\n",
       "      <td>-0.554473</td>\n",
       "      <td>-0.254278</td>\n",
       "      <td>0.013919</td>\n",
       "      <td>0.327864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152302</td>\n",
       "      <td>-0.079568</td>\n",
       "      <td>-0.250151</td>\n",
       "      <td>-0.107531</td>\n",
       "      <td>-0.245801</td>\n",
       "      <td>-0.080958</td>\n",
       "      <td>-0.214992</td>\n",
       "      <td>0.242315</td>\n",
       "      <td>0.214886</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.730490</td>\n",
       "      <td>-2.336966</td>\n",
       "      <td>-0.197357</td>\n",
       "      <td>-0.099710</td>\n",
       "      <td>0.042322</td>\n",
       "      <td>0.420716</td>\n",
       "      <td>-0.017422</td>\n",
       "      <td>0.020909</td>\n",
       "      <td>-0.061947</td>\n",
       "      <td>0.226997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255886</td>\n",
       "      <td>0.141114</td>\n",
       "      <td>-0.059088</td>\n",
       "      <td>0.066955</td>\n",
       "      <td>0.151233</td>\n",
       "      <td>-0.073002</td>\n",
       "      <td>-0.184407</td>\n",
       "      <td>0.052280</td>\n",
       "      <td>-0.046525</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.563922</td>\n",
       "      <td>0.724388</td>\n",
       "      <td>0.908377</td>\n",
       "      <td>-2.165524</td>\n",
       "      <td>2.412024</td>\n",
       "      <td>-0.565519</td>\n",
       "      <td>0.513390</td>\n",
       "      <td>-0.153776</td>\n",
       "      <td>-0.250971</td>\n",
       "      <td>0.204393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168926</td>\n",
       "      <td>-0.169644</td>\n",
       "      <td>-0.052725</td>\n",
       "      <td>-0.057067</td>\n",
       "      <td>-0.293405</td>\n",
       "      <td>-0.034748</td>\n",
       "      <td>0.018079</td>\n",
       "      <td>0.238624</td>\n",
       "      <td>-0.152767</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.057953</td>\n",
       "      <td>-0.408774</td>\n",
       "      <td>1.099041</td>\n",
       "      <td>-0.598434</td>\n",
       "      <td>-0.205021</td>\n",
       "      <td>0.854135</td>\n",
       "      <td>-0.445132</td>\n",
       "      <td>-0.308015</td>\n",
       "      <td>0.131580</td>\n",
       "      <td>-0.219747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049617</td>\n",
       "      <td>0.183280</td>\n",
       "      <td>-0.065502</td>\n",
       "      <td>-0.033485</td>\n",
       "      <td>0.071344</td>\n",
       "      <td>-0.035859</td>\n",
       "      <td>-0.062878</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>-0.005593</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.676309</td>\n",
       "      <td>-4.075108</td>\n",
       "      <td>-1.300399</td>\n",
       "      <td>0.403183</td>\n",
       "      <td>-0.811104</td>\n",
       "      <td>-0.677178</td>\n",
       "      <td>0.810935</td>\n",
       "      <td>-0.066891</td>\n",
       "      <td>0.501818</td>\n",
       "      <td>0.045705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027678</td>\n",
       "      <td>-0.092043</td>\n",
       "      <td>0.095098</td>\n",
       "      <td>-0.057876</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.088755</td>\n",
       "      <td>-0.010662</td>\n",
       "      <td>-0.012330</td>\n",
       "      <td>-0.003450</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>-1.677530</td>\n",
       "      <td>2.298283</td>\n",
       "      <td>-2.470454</td>\n",
       "      <td>-0.711787</td>\n",
       "      <td>-0.034619</td>\n",
       "      <td>0.018352</td>\n",
       "      <td>0.011348</td>\n",
       "      <td>-0.178542</td>\n",
       "      <td>-0.217511</td>\n",
       "      <td>-0.075501</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098593</td>\n",
       "      <td>-0.068376</td>\n",
       "      <td>0.049699</td>\n",
       "      <td>0.072006</td>\n",
       "      <td>-0.001584</td>\n",
       "      <td>-0.093042</td>\n",
       "      <td>-0.140242</td>\n",
       "      <td>-0.123634</td>\n",
       "      <td>0.072497</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>2.563273</td>\n",
       "      <td>0.642886</td>\n",
       "      <td>-0.114482</td>\n",
       "      <td>2.374667</td>\n",
       "      <td>0.664604</td>\n",
       "      <td>2.437336</td>\n",
       "      <td>2.402342</td>\n",
       "      <td>0.822720</td>\n",
       "      <td>0.693345</td>\n",
       "      <td>0.205482</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191605</td>\n",
       "      <td>-0.349451</td>\n",
       "      <td>0.191343</td>\n",
       "      <td>0.571275</td>\n",
       "      <td>-0.203902</td>\n",
       "      <td>0.276381</td>\n",
       "      <td>0.084063</td>\n",
       "      <td>-0.088606</td>\n",
       "      <td>-0.051174</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>1.061600</td>\n",
       "      <td>-2.832661</td>\n",
       "      <td>-0.617288</td>\n",
       "      <td>-0.625660</td>\n",
       "      <td>-1.056084</td>\n",
       "      <td>-1.082804</td>\n",
       "      <td>-0.204459</td>\n",
       "      <td>0.854091</td>\n",
       "      <td>-0.230621</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007717</td>\n",
       "      <td>0.205836</td>\n",
       "      <td>-0.230538</td>\n",
       "      <td>0.077988</td>\n",
       "      <td>-0.344476</td>\n",
       "      <td>0.214487</td>\n",
       "      <td>0.256306</td>\n",
       "      <td>-0.181507</td>\n",
       "      <td>-0.206344</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>6.325581</td>\n",
       "      <td>-0.844124</td>\n",
       "      <td>-1.197173</td>\n",
       "      <td>0.377364</td>\n",
       "      <td>-1.109529</td>\n",
       "      <td>-0.497345</td>\n",
       "      <td>-0.451555</td>\n",
       "      <td>0.381003</td>\n",
       "      <td>-0.173963</td>\n",
       "      <td>-0.055648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031517</td>\n",
       "      <td>0.116338</td>\n",
       "      <td>-0.223165</td>\n",
       "      <td>-0.094717</td>\n",
       "      <td>0.048993</td>\n",
       "      <td>-0.288996</td>\n",
       "      <td>-0.059291</td>\n",
       "      <td>0.138696</td>\n",
       "      <td>0.038389</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>1.833709</td>\n",
       "      <td>-3.291351</td>\n",
       "      <td>-0.193554</td>\n",
       "      <td>0.589598</td>\n",
       "      <td>0.168293</td>\n",
       "      <td>-0.764108</td>\n",
       "      <td>0.342735</td>\n",
       "      <td>0.124753</td>\n",
       "      <td>-0.555976</td>\n",
       "      <td>-0.264147</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122895</td>\n",
       "      <td>-0.172447</td>\n",
       "      <td>-0.224528</td>\n",
       "      <td>-0.138194</td>\n",
       "      <td>0.087539</td>\n",
       "      <td>-0.131240</td>\n",
       "      <td>0.190355</td>\n",
       "      <td>-0.036732</td>\n",
       "      <td>0.062887</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5400 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.128476 -0.953553  2.484261 -0.938782  0.429984  0.378784 -0.554473   \n",
       "1     0.730490 -2.336966 -0.197357 -0.099710  0.042322  0.420716 -0.017422   \n",
       "2     0.563922  0.724388  0.908377 -2.165524  2.412024 -0.565519  0.513390   \n",
       "3    -0.057953 -0.408774  1.099041 -0.598434 -0.205021  0.854135 -0.445132   \n",
       "4    -5.676309 -4.075108 -1.300399  0.403183 -0.811104 -0.677178  0.810935   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5395 -1.677530  2.298283 -2.470454 -0.711787 -0.034619  0.018352  0.011348   \n",
       "5396  2.563273  0.642886 -0.114482  2.374667  0.664604  2.437336  2.402342   \n",
       "5397  1.061600 -2.832661 -0.617288 -0.625660 -1.056084 -1.082804 -0.204459   \n",
       "5398  6.325581 -0.844124 -1.197173  0.377364 -1.109529 -0.497345 -0.451555   \n",
       "5399  1.833709 -3.291351 -0.193554  0.589598  0.168293 -0.764108  0.342735   \n",
       "\n",
       "            7         8         9   ...        11        12        13  \\\n",
       "0    -0.254278  0.013919  0.327864  ...  0.152302 -0.079568 -0.250151   \n",
       "1     0.020909 -0.061947  0.226997  ... -0.255886  0.141114 -0.059088   \n",
       "2    -0.153776 -0.250971  0.204393  ... -0.168926 -0.169644 -0.052725   \n",
       "3    -0.308015  0.131580 -0.219747  ... -0.049617  0.183280 -0.065502   \n",
       "4    -0.066891  0.501818  0.045705  ...  0.027678 -0.092043  0.095098   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5395 -0.178542 -0.217511 -0.075501  ... -0.098593 -0.068376  0.049699   \n",
       "5396  0.822720  0.693345  0.205482  ... -0.191605 -0.349451  0.191343   \n",
       "5397  0.854091 -0.230621  0.008330  ... -0.007717  0.205836 -0.230538   \n",
       "5398  0.381003 -0.173963 -0.055648  ...  0.031517  0.116338 -0.223165   \n",
       "5399  0.124753 -0.555976 -0.264147  ... -0.122895 -0.172447 -0.224528   \n",
       "\n",
       "            14        15        16        17        18        19   0   \n",
       "0    -0.107531 -0.245801 -0.080958 -0.214992  0.242315  0.214886  1.0  \n",
       "1     0.066955  0.151233 -0.073002 -0.184407  0.052280 -0.046525  1.0  \n",
       "2    -0.057067 -0.293405 -0.034748  0.018079  0.238624 -0.152767  1.0  \n",
       "3    -0.033485  0.071344 -0.035859 -0.062878  0.006159 -0.005593  1.0  \n",
       "4    -0.057876  0.002760  0.088755 -0.010662 -0.012330 -0.003450  1.0  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "5395  0.072006 -0.001584 -0.093042 -0.140242 -0.123634  0.072497  0.0  \n",
       "5396  0.571275 -0.203902  0.276381  0.084063 -0.088606 -0.051174  0.0  \n",
       "5397  0.077988 -0.344476  0.214487  0.256306 -0.181507 -0.206344  0.0  \n",
       "5398 -0.094717  0.048993 -0.288996 -0.059291  0.138696  0.038389  0.0  \n",
       "5399 -0.138194  0.087539 -0.131240  0.190355 -0.036732  0.062887  0.0  \n",
       "\n",
       "[5400 rows x 21 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#appending the label column to the dataframe.\n",
    "label_column = pd.concat([new_scalardata, pd.DataFrame(y)],axis=1)\n",
    "label_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c64bd90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the dataframe as as csv file.\n",
    "csv_data=label_column.to_csv('Downloads\\FinalPCA(p&c).csv', mode='a',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59f1278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the final training data.\n",
    "train_data = pd.read_csv('Downloads\\FinalPCA(p&c).csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41adf9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.128476</td>\n",
       "      <td>-0.953553</td>\n",
       "      <td>2.484261</td>\n",
       "      <td>-0.938782</td>\n",
       "      <td>0.429984</td>\n",
       "      <td>0.378784</td>\n",
       "      <td>-0.554473</td>\n",
       "      <td>-0.254278</td>\n",
       "      <td>0.013919</td>\n",
       "      <td>0.327864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152302</td>\n",
       "      <td>-0.079568</td>\n",
       "      <td>-0.250151</td>\n",
       "      <td>-0.107531</td>\n",
       "      <td>-0.245801</td>\n",
       "      <td>-0.080958</td>\n",
       "      <td>-0.214992</td>\n",
       "      <td>0.242315</td>\n",
       "      <td>0.214886</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.730490</td>\n",
       "      <td>-2.336966</td>\n",
       "      <td>-0.197357</td>\n",
       "      <td>-0.099710</td>\n",
       "      <td>0.042322</td>\n",
       "      <td>0.420716</td>\n",
       "      <td>-0.017422</td>\n",
       "      <td>0.020909</td>\n",
       "      <td>-0.061947</td>\n",
       "      <td>0.226997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255886</td>\n",
       "      <td>0.141114</td>\n",
       "      <td>-0.059088</td>\n",
       "      <td>0.066955</td>\n",
       "      <td>0.151233</td>\n",
       "      <td>-0.073002</td>\n",
       "      <td>-0.184407</td>\n",
       "      <td>0.052280</td>\n",
       "      <td>-0.046525</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.563922</td>\n",
       "      <td>0.724388</td>\n",
       "      <td>0.908377</td>\n",
       "      <td>-2.165524</td>\n",
       "      <td>2.412024</td>\n",
       "      <td>-0.565519</td>\n",
       "      <td>0.513390</td>\n",
       "      <td>-0.153776</td>\n",
       "      <td>-0.250971</td>\n",
       "      <td>0.204393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168926</td>\n",
       "      <td>-0.169644</td>\n",
       "      <td>-0.052725</td>\n",
       "      <td>-0.057067</td>\n",
       "      <td>-0.293405</td>\n",
       "      <td>-0.034748</td>\n",
       "      <td>0.018079</td>\n",
       "      <td>0.238624</td>\n",
       "      <td>-0.152767</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.057953</td>\n",
       "      <td>-0.408774</td>\n",
       "      <td>1.099041</td>\n",
       "      <td>-0.598434</td>\n",
       "      <td>-0.205021</td>\n",
       "      <td>0.854135</td>\n",
       "      <td>-0.445132</td>\n",
       "      <td>-0.308015</td>\n",
       "      <td>0.131580</td>\n",
       "      <td>-0.219747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049617</td>\n",
       "      <td>0.183280</td>\n",
       "      <td>-0.065502</td>\n",
       "      <td>-0.033485</td>\n",
       "      <td>0.071344</td>\n",
       "      <td>-0.035859</td>\n",
       "      <td>-0.062878</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>-0.005593</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.676309</td>\n",
       "      <td>-4.075108</td>\n",
       "      <td>-1.300399</td>\n",
       "      <td>0.403183</td>\n",
       "      <td>-0.811104</td>\n",
       "      <td>-0.677178</td>\n",
       "      <td>0.810935</td>\n",
       "      <td>-0.066891</td>\n",
       "      <td>0.501818</td>\n",
       "      <td>0.045705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027678</td>\n",
       "      <td>-0.092043</td>\n",
       "      <td>0.095098</td>\n",
       "      <td>-0.057876</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.088755</td>\n",
       "      <td>-0.010662</td>\n",
       "      <td>-0.012330</td>\n",
       "      <td>-0.003450</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>-1.677530</td>\n",
       "      <td>2.298283</td>\n",
       "      <td>-2.470454</td>\n",
       "      <td>-0.711787</td>\n",
       "      <td>-0.034619</td>\n",
       "      <td>0.018352</td>\n",
       "      <td>0.011348</td>\n",
       "      <td>-0.178542</td>\n",
       "      <td>-0.217511</td>\n",
       "      <td>-0.075501</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098593</td>\n",
       "      <td>-0.068376</td>\n",
       "      <td>0.049699</td>\n",
       "      <td>0.072006</td>\n",
       "      <td>-0.001584</td>\n",
       "      <td>-0.093042</td>\n",
       "      <td>-0.140242</td>\n",
       "      <td>-0.123634</td>\n",
       "      <td>0.072497</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>2.563273</td>\n",
       "      <td>0.642886</td>\n",
       "      <td>-0.114482</td>\n",
       "      <td>2.374667</td>\n",
       "      <td>0.664604</td>\n",
       "      <td>2.437336</td>\n",
       "      <td>2.402342</td>\n",
       "      <td>0.822720</td>\n",
       "      <td>0.693345</td>\n",
       "      <td>0.205482</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191605</td>\n",
       "      <td>-0.349451</td>\n",
       "      <td>0.191343</td>\n",
       "      <td>0.571275</td>\n",
       "      <td>-0.203902</td>\n",
       "      <td>0.276381</td>\n",
       "      <td>0.084063</td>\n",
       "      <td>-0.088606</td>\n",
       "      <td>-0.051174</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>1.061600</td>\n",
       "      <td>-2.832661</td>\n",
       "      <td>-0.617288</td>\n",
       "      <td>-0.625660</td>\n",
       "      <td>-1.056084</td>\n",
       "      <td>-1.082804</td>\n",
       "      <td>-0.204459</td>\n",
       "      <td>0.854091</td>\n",
       "      <td>-0.230621</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007717</td>\n",
       "      <td>0.205836</td>\n",
       "      <td>-0.230538</td>\n",
       "      <td>0.077988</td>\n",
       "      <td>-0.344476</td>\n",
       "      <td>0.214487</td>\n",
       "      <td>0.256306</td>\n",
       "      <td>-0.181507</td>\n",
       "      <td>-0.206344</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>6.325581</td>\n",
       "      <td>-0.844124</td>\n",
       "      <td>-1.197173</td>\n",
       "      <td>0.377364</td>\n",
       "      <td>-1.109529</td>\n",
       "      <td>-0.497345</td>\n",
       "      <td>-0.451555</td>\n",
       "      <td>0.381003</td>\n",
       "      <td>-0.173963</td>\n",
       "      <td>-0.055648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031517</td>\n",
       "      <td>0.116338</td>\n",
       "      <td>-0.223165</td>\n",
       "      <td>-0.094717</td>\n",
       "      <td>0.048993</td>\n",
       "      <td>-0.288996</td>\n",
       "      <td>-0.059291</td>\n",
       "      <td>0.138696</td>\n",
       "      <td>0.038389</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>1.833709</td>\n",
       "      <td>-3.291351</td>\n",
       "      <td>-0.193554</td>\n",
       "      <td>0.589598</td>\n",
       "      <td>0.168293</td>\n",
       "      <td>-0.764108</td>\n",
       "      <td>0.342735</td>\n",
       "      <td>0.124753</td>\n",
       "      <td>-0.555976</td>\n",
       "      <td>-0.264147</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122895</td>\n",
       "      <td>-0.172447</td>\n",
       "      <td>-0.224528</td>\n",
       "      <td>-0.138194</td>\n",
       "      <td>0.087539</td>\n",
       "      <td>-0.131240</td>\n",
       "      <td>0.190355</td>\n",
       "      <td>-0.036732</td>\n",
       "      <td>0.062887</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5400 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.128476 -0.953553  2.484261 -0.938782  0.429984  0.378784 -0.554473   \n",
       "1     0.730490 -2.336966 -0.197357 -0.099710  0.042322  0.420716 -0.017422   \n",
       "2     0.563922  0.724388  0.908377 -2.165524  2.412024 -0.565519  0.513390   \n",
       "3    -0.057953 -0.408774  1.099041 -0.598434 -0.205021  0.854135 -0.445132   \n",
       "4    -5.676309 -4.075108 -1.300399  0.403183 -0.811104 -0.677178  0.810935   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5395 -1.677530  2.298283 -2.470454 -0.711787 -0.034619  0.018352  0.011348   \n",
       "5396  2.563273  0.642886 -0.114482  2.374667  0.664604  2.437336  2.402342   \n",
       "5397  1.061600 -2.832661 -0.617288 -0.625660 -1.056084 -1.082804 -0.204459   \n",
       "5398  6.325581 -0.844124 -1.197173  0.377364 -1.109529 -0.497345 -0.451555   \n",
       "5399  1.833709 -3.291351 -0.193554  0.589598  0.168293 -0.764108  0.342735   \n",
       "\n",
       "            7         8         9   ...        11        12        13  \\\n",
       "0    -0.254278  0.013919  0.327864  ...  0.152302 -0.079568 -0.250151   \n",
       "1     0.020909 -0.061947  0.226997  ... -0.255886  0.141114 -0.059088   \n",
       "2    -0.153776 -0.250971  0.204393  ... -0.168926 -0.169644 -0.052725   \n",
       "3    -0.308015  0.131580 -0.219747  ... -0.049617  0.183280 -0.065502   \n",
       "4    -0.066891  0.501818  0.045705  ...  0.027678 -0.092043  0.095098   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5395 -0.178542 -0.217511 -0.075501  ... -0.098593 -0.068376  0.049699   \n",
       "5396  0.822720  0.693345  0.205482  ... -0.191605 -0.349451  0.191343   \n",
       "5397  0.854091 -0.230621  0.008330  ... -0.007717  0.205836 -0.230538   \n",
       "5398  0.381003 -0.173963 -0.055648  ...  0.031517  0.116338 -0.223165   \n",
       "5399  0.124753 -0.555976 -0.264147  ... -0.122895 -0.172447 -0.224528   \n",
       "\n",
       "            14        15        16        17        18        19   20  \n",
       "0    -0.107531 -0.245801 -0.080958 -0.214992  0.242315  0.214886  1.0  \n",
       "1     0.066955  0.151233 -0.073002 -0.184407  0.052280 -0.046525  1.0  \n",
       "2    -0.057067 -0.293405 -0.034748  0.018079  0.238624 -0.152767  1.0  \n",
       "3    -0.033485  0.071344 -0.035859 -0.062878  0.006159 -0.005593  1.0  \n",
       "4    -0.057876  0.002760  0.088755 -0.010662 -0.012330 -0.003450  1.0  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "5395  0.072006 -0.001584 -0.093042 -0.140242 -0.123634  0.072497  0.0  \n",
       "5396  0.571275 -0.203902  0.276381  0.084063 -0.088606 -0.051174  0.0  \n",
       "5397  0.077988 -0.344476  0.214487  0.256306 -0.181507 -0.206344  0.0  \n",
       "5398 -0.094717  0.048993 -0.288996 -0.059291  0.138696  0.038389  0.0  \n",
       "5399 -0.138194  0.087539 -0.131240  0.190355 -0.036732  0.062887  0.0  \n",
       "\n",
       "[5400 rows x 21 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "784b652f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X values\n",
      "[[ 0.12847608 -0.95355303  2.484261   ... -0.21499233  0.24231463\n",
      "   0.21488625]\n",
      " [ 0.73049003 -2.33696554 -0.19735678 ... -0.18440678  0.05228022\n",
      "  -0.04652485]\n",
      " [ 0.56392168  0.72438825  0.90837748 ...  0.0180794   0.23862358\n",
      "  -0.15276742]\n",
      " ...\n",
      " [ 1.06160004 -2.83266057 -0.61728757 ...  0.25630618 -0.18150717\n",
      "  -0.20634408]\n",
      " [ 6.32558139 -0.8441239  -1.19717324 ... -0.05929087  0.13869582\n",
      "   0.03838929]\n",
      " [ 1.83370913 -3.29135138 -0.19355436 ...  0.19035461 -0.03673238\n",
      "   0.06288735]]\n",
      "Y values\n",
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "5395    0.0\n",
      "5396    0.0\n",
      "5397    0.0\n",
      "5398    0.0\n",
      "5399    0.0\n",
      "Name: 20, Length: 5400, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#assigning x the columns from 1 to 18 for training\n",
    "x = train_data.iloc[:,0:20].values\n",
    "print(\"X values\")\n",
    "print(x)\n",
    "\n",
    "#assigning y with the column \"Class\" as target variable\n",
    "y = train_data.iloc[:,20]\n",
    "print(\"Y values\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81ea632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset split into train and test with 80% Training and 20% Testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50e5f508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results\n",
      "Decision Tree Accuracy:  76.38888888888889 %\n",
      "Train Accuracy: 0.9569444444444445\n",
      "Test Accuracy: 0.7638888888888888\n",
      "Precision Score:  0.7638888888888888\n",
      "Recall Score:  0.7638888888888888\n",
      "F2 Score:  0.7638888888888888\n",
      "F1 Score:  0.763888888888889\n",
      "Confusion Matrix: \n",
      "[[411 130]\n",
      " [125 414]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#Assign model with Decision Tree classifier\n",
    "model_dt = DecisionTreeClassifier(max_depth=11)\n",
    "#training the model with the Training Variables \n",
    "model_dt.fit(x_train, y_train)\n",
    "#dumping the decision tree classifier model to the disk\n",
    "joblib.dump(model_dt,\"model_dt\")\n",
    "#predicting the target variable using testing variables\n",
    "y_pred1 = model_dt.predict(x_test)\n",
    "#Results\n",
    "print(\"Decision Tree Results\")\n",
    "print(\"Decision Tree Accuracy: \",accuracy_score(y_test, y_pred1)*100,\"%\")\n",
    "print(\"Train Accuracy:\",model_dt.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model_dt.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred1, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred1, pos_label='positive', average='micro')) # true positive rate, Sensitivity\n",
    "print(\"F2 Score: \",metrics.fbeta_score(y_test, y_pred1, pos_label='positive', average='micro', beta=2.0))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred1, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0be36a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Clasifier\n",
      "Train Accuracy: 0.999537037037037\n",
      "Test Accuracy: 81.48148148148148\n",
      "Precision Score:  0.8148148148148148\n",
      "Recall Score:  0.8148148148148148\n",
      "F1 Score:  0.8148148148148148\n",
      "Confusion Matrix: \n",
      "[[450  91]\n",
      " [109 430]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "#Random Forest classifier\n",
    "model_rf = RandomForestClassifier(n_estimators = 100)\n",
    "#training the model with train variables\n",
    "model_rf.fit(x_train, y_train)\n",
    "#dumping the random forest classifier model to the disk\n",
    "joblib.dump(model_rf,\"model_rf\")\n",
    "#predicting with the trained random forest model\n",
    "y_pred2 = model_rf.predict(x_test)\n",
    "print(\"Random Forest Clasifier\")\n",
    "print(\"Train Accuracy:\",model_rf.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model_rf.score(x_test, y_test)*100)\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred2, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred2, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred2, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5f5f67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "Train Accuracy: 0.819212962962963\n",
      "Test Accuracy: 76.11111111111111\n",
      "Precision Score:  0.7611111111111111\n",
      "Recall Score:  0.7611111111111111\n",
      "F1 Score:  0.7611111111111111\n",
      "Confusion Matrix: \n",
      "[[448  93]\n",
      " [165 374]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "#KNN classifier\n",
    "model_knn = KNeighborsClassifier(n_neighbors = 8)\n",
    "model_knn.fit(x_train, y_train)\n",
    "#dumping the KNN classifier model to the disk.\n",
    "joblib.dump(model_knn,\"model_knn\")\n",
    "y_pred3 = model_knn.predict(x_test)\n",
    "print(\"KNN\")\n",
    "print(\"Train Accuracy:\",model_knn.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model_knn.score(x_test, y_test)*100)\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f15f4bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Linear kernel\n",
      "Train Accuracy: 0.8319444444444445\n",
      "Test Accuracy: 80.0\n",
      "Precision Score:  0.8\n",
      "Recall Score:  0.8\n",
      "F1 Score:  0.8000000000000002\n",
      "Confusion Matrix: \n",
      "[[446  95]\n",
      " [121 418]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "#svm classifier\n",
    "model_svm = svm.SVC(kernel='rbf') # rbf Kernel\n",
    "model_svm.fit(x_train, y_train)\n",
    "#dumping the svm classifier model to the disk\n",
    "joblib.dump(model_svm,\"model_svm\")\n",
    "#prediction\n",
    "y_pred4 = model_svm.predict(x_test)\n",
    "print(\"SVM Linear kernel\")\n",
    "print(\"Train Accuracy:\",model_svm.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model_svm.score(x_test, y_test)*100)\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred4, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred4, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred4, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57d7386c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB\n",
      "Train Accuracy: 0.7951388888888888\n",
      "Test Accuracy: 76.85185185185185\n",
      "Precision Score:  0.7685185185185185\n",
      "Recall Score:  0.7685185185185185\n",
      "F1 Score:  0.7685185185185186\n",
      "Confusion Matrix: \n",
      "[[434 107]\n",
      " [143 396]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "#gaussian naive bayes classifier\n",
    "model_nb = GaussianNB().fit(x_train, y_train)\n",
    "#dumping the naive bayes classifier model to the disk\n",
    "joblib.dump(model_nb,\"model_nb\")\n",
    "y_pred8 = model_nb.predict(x_test)\n",
    "print(\"Gaussian NB\")\n",
    "print(\"Train Accuracy:\",model_nb.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model_nb.score(x_test, y_test)*100)\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred8, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred8, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred8, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred8,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f06ac496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGboost\n",
      "Train Accuracy: 0.999537037037037\n",
      "Test Accuracy: 82.5925925925926\n",
      "Precision Score:  0.825925925925926\n",
      "Recall Score:  0.825925925925926\n",
      "F1 Score:  0.825925925925926\n",
      "Confusion Matrix: \n",
      "[[446  95]\n",
      " [ 93 446]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/home/admin-/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1298: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "#xgboost classifier\n",
    "model_xgboost = XGBClassifier().fit(x_train, y_train)\n",
    "#dumping the xgboost classifier model to the disk.\n",
    "joblib.dump(model_nb,\"model_xgboost\")\n",
    "#prediction\n",
    "y_pred5 = model_xgboost.predict(x_test)\n",
    "print(\"XGboost\")\n",
    "print(\"Train Accuracy:\",model_xgboost.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model_xgboost.score(x_test, y_test)*100)\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred5, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred5, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred5, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ce0a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa38a6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56635fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de84a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb59d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e62180c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
